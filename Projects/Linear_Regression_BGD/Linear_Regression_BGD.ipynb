{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJHxqfwMOlew"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = data.data, data.target\n",
        "print(data.data[0])\n",
        "scaler = StandardScaler()\n",
        "X[:, 1:] = scaler.fit_transform(X[:, 1:]) # blows up to infinity or NaN with out this function, which sets mean to 0 and stand deviation to 1, to normalise the data without using max values (potential anomalies) to normalise range between -1 and 1\n",
        "print(X[1])"
      ],
      "metadata": {
        "id": "uV_ejSq_Oxyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bff859eb-df71-42d0-d8b9-f4af46cebc46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   8.3252       41.            6.98412698    1.02380952  322.\n",
            "    2.55555556   37.88       -122.23      ]\n",
            "[ 8.3014     -0.60701891  0.32704136 -0.26333577  0.86143887 -0.09251223\n",
            "  1.04318455 -1.32284391]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X[:, 1:] = scaler.fit_transform(X[:, 1:])\n",
        "X = np.c_[np.ones(X.shape[0]), X]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "aN2cCGpVB26O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXmaQeSbCYpI",
        "outputId": "7bd5b24e-8984-41bd-ea41-6c789b4a5c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.          8.3252      0.98214266  0.62855945 -0.15375759 -0.9744286\n",
            " -0.04959654  1.05254828 -1.32783522]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=0.0005/len(y)\n",
        "epochs = 10000\n",
        "m = len(y)"
      ],
      "metadata": {
        "id": "-yt6dw6olAur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class linearRegression:\n",
        "  def __init__(self, x):\n",
        "    self.theta = np.random.uniform(low=-1, high=1, size=(x.shape[1], 1))\n",
        "\n",
        "  def hypothesis(self,X):\n",
        "    # print(X.shape, self.theta.shape, (X @ self.theta).shape)\n",
        "    return X @ self.theta\n",
        "  def evaluate(self,x, y):\n",
        "    predictions = self.hypothesis(x)\n",
        "    mse = mean_squared_error(y, predictions)\n",
        "    print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "  def step(self, alpha, X, y):\n",
        "    predictions = self.hypothesis(X)\n",
        "    error = y.reshape(-1, 1) - predictions\n",
        "    # print('xte',X.T.shape, error.shape)\n",
        "    gradient = (X.T @ error)\n",
        "    self.theta += alpha * gradient\n",
        "\n",
        "  def train(self, X, y, lr, epochs):\n",
        "    for epoch in range(epochs):\n",
        "      self.step(lr, X, y)\n",
        "      if epoch % 1000 == 0:\n",
        "        print('epoch:',epoch)\n",
        "        self.evaluate(X_test, y_test)\n",
        "\n",
        "linReg = linearRegression(X_train)"
      ],
      "metadata": {
        "id": "ZJsrpFxuO1Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linReg.train(X_train, y_train, learning_rate, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Lk5APO2qpTnh",
        "outputId": "10ef631d-3d86-4002-ab85-234695170e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\n",
            "Mean Squared Error: 0.6336508238640411\n",
            "epoch: 1000\n",
            "Mean Squared Error: 0.6272299381564067\n",
            "epoch: 2000\n",
            "Mean Squared Error: 0.6212959138179752\n",
            "epoch: 3000\n",
            "Mean Squared Error: 0.6157927511041829\n",
            "epoch: 4000\n",
            "Mean Squared Error: 0.6106787684240359\n",
            "epoch: 5000\n",
            "Mean Squared Error: 0.6059208724385046\n",
            "epoch: 6000\n",
            "Mean Squared Error: 0.6014913646498938\n",
            "epoch: 7000\n",
            "Mean Squared Error: 0.5973661410283927\n",
            "epoch: 8000\n",
            "Mean Squared Error: 0.5935236656240497\n",
            "epoch: 9000\n",
            "Mean Squared Error: 0.5899443745429539\n"
          ]
        }
      ]
    }
  ]
}